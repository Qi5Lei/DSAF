DATA_ROOT: '../datasets/'
LOGS_ROOT: '../logs/'


MODEL:
  # architecture
  backbone: 'resnet50'
  pooling: 'gem'
  embed_feat: 0
  dropout: 0.
  ibn_layers: ['layer1','layer2','layer3','layer4',]

  dsbn: True
  ibn_f: 20
  pre_trained: ###

  sync_bn: True
  samples_per_bn: 16

  mean_net: False
  alpha: 0.999

  # pretraining
  imagenet_pretrained: True
  source_pretrained: null


DATA:

  height: 256
  width: 128
  norm_mean: [0.485, 0.456, 0.406]
  norm_std: [0.229, 0.224, 0.225]

  TRAIN:
    # augmentation
    is_autoaug: False

    is_flip: True
    flip_prob: 0.5

    is_pad: True
    pad_size: 10

    is_blur: False
    blur_prob: 0.5

    is_erase: False
    erase_prob: 0.5

    # dual augmentation for MMT
    is_mutual_transform: False
    mutual_times: 2


TRAIN:
  seed: 1
  deterministic: True
  # mixed precision training for PyTorch>=1.6
  amp: False
  ####################################################
  # datasets
  datasets: { 'dukemtmcreid': 'trainval','market1501': 'trainval',}  #'dukemtmcreid': 'trainval',
  #datasets: {'market1501': 'trainval'}
  unsup_dataset_indexes: [0, 1]   #####*********CCCCCC

  epochs: 50
  iters: 400
  LOSS:
    losses: {'cross_entropy': 1., 'softmax_triplet': 1.}
    margin: 0.
####################################################
  # validate
  val_dataset: ['market1501', 'dukemtmcreid',] #['dukemtmcreid', 'market1501']
  val_freq: 1

  # sampler
  SAMPLER:
    num_instances: 4
    is_shuffle: True

  # data loader
  LOADER:
    samples_per_gpu: 16
    workers_per_gpu: 2

  # pseudo labels
  PSEUDO_LABELS:
    freq: 1 # epochs############&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
    use_outliers: False
    norm_feat: True
    norm_center: True

    cluster: 'dbscan'
    eps: [0.6,]
    min_samples: 4 # for dbscan
    dist_metric: 'jaccard'
    k1: 30 # for jaccard distance
    k2: 6 # for jaccard distance
    search_type: 0 # 0,1,2 for GPU, 3 for CPU (work for faiss)
    cluster_num: null

    # cluster: 'kmeans'
    # cluster_num: [500,]
    # dist_cuda: True

  # optim
  OPTIM:
    optim: 'adam'
    lr: 0.00035
    weight_decay: 0.0005

  SCHEDULER:
    lr_scheduler: null


TEST:
####################################################
  # datasets
  datasets: ['msmt17',] #market1501
  fusion: True

  # data loader
  LOADER:
    samples_per_gpu: 32
    workers_per_gpu: 2

  # ranking setting
  dist_metric: 'euclidean'
  norm_feat: True
  dist_cuda: True

  # post processing
  rerank: False
  search_type: 0 # 0,1,2 for GPU, 3 for CPU (work for faiss)
  k1: 20
  k2: 6
  lambda_value: 0.3
